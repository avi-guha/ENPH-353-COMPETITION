{
  "episode_rewards": [
    -1528.0,
    -1895.0,
    -230.0,
    -1910.0,
    1293.0,
    -1727.0,
    -2030.0,
    928.0,
    -2310.0
  ],
  "episode_lengths": [
    25,
    40,
    56,
    38,
    66,
    71,
    47,
    57,
    48
  ],
  "losses": [
    0,
    52.02180862426758,
    50.813364369528635,
    46.55223705894068,
    37.61125541455818,
    36.13386202530122,
    33.33039754502317,
    32.21386989794279,
    30.88458526134491
  ],
  "epsilon_history": [
    0.995,
    0.990025,
    0.985074875,
    0.9801495006250001,
    0.9752487531218751,
    0.9703725093562657,
    0.9655206468094844,
    0.960693043575437,
    0.9558895783575597
  ],
  "agent_metrics": {
    "epsilon": 0.9558895783575597,
    "training_step": 407,
    "episode_count": 9,
    "buffer_size": 470
  }
}