{
  "episode_rewards": [
    -1650.0,
    -1405.0,
    -1906.0,
    -1278.0,
    -1148.0,
    -1791.0,
    -1405.0,
    -2264.0,
    -2748.0,
    -1885.0,
    -2094.0,
    -1086.0,
    -2666.0,
    -1591.0,
    -182.0,
    -3845.0,
    -1635.0,
    -111.0
  ],
  "episode_lengths": [
    61,
    24,
    47,
    42,
    41,
    41,
    44,
    71,
    79,
    37,
    71,
    54,
    81,
    57,
    47,
    181,
    85,
    56
  ],
  "losses": [
    0,
    34.17903830788352,
    37.265588882121634,
    31.849224817185174,
    29.07992828183058,
    26.089771759219285,
    23.56428324092518,
    23.198343612778356,
    20.32937258708326,
    20.143779960838526,
    24.420793869126012,
    21.28249325575652,
    21.21421029832628,
    19.26006701954624,
    21.45054839519744,
    20.48587019535718,
    22.41592327566708,
    19.86707191807883
  ],
  "epsilon_history": [
    0.995,
    0.990025,
    0.985074875,
    0.9801495006250001,
    0.9752487531218751,
    0.9703725093562657,
    0.9655206468094844,
    0.960693043575437,
    0.9558895783575597,
    0.9511101304657719,
    0.946354579813443,
    0.9416228069143757,
    0.9369146928798039,
    0.9322301194154049,
    0.9275689688183278,
    0.9229311239742362,
    0.918316468354365,
    0.9137248860125932
  ],
  "agent_metrics": {
    "epsilon": 0.9137248860125932,
    "training_step": 1094,
    "episode_count": 18,
    "buffer_size": 1157
  }
}