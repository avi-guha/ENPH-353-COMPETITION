{
  "episode_rewards": [
    -1174.0,
    -1355.0,
    -1254.0,
    -1921.0,
    -1760.0,
    -683.0,
    -1730.0,
    -2315.0,
    -1385.0,
    -1582.0,
    -2239.0,
    -1350.0,
    -603.0,
    -1592.0,
    -1092.0,
    -1083.0,
    -730.0,
    -665.0,
    -262.0,
    -2219.0,
    -2280.0,
    -1725.0,
    -1920.0,
    -1091.0,
    -1795.0
  ],
  "episode_lengths": [
    65,
    27,
    54,
    82,
    58,
    50,
    41,
    49,
    25,
    78,
    73,
    34,
    54,
    88,
    50,
    61,
    12,
    59,
    54,
    80,
    50,
    36,
    43,
    61,
    43
  ],
  "losses": [
    42.05315589904785,
    42.58352745903863,
    40.34006115242287,
    29.06899305669273,
    27.49920448763617,
    26.812225151062012,
    25.27263241279416,
    25.87500015570193,
    24.160944061279295,
    24.08152121763963,
    27.807522381821723,
    24.942371508654425,
    25.813730151564986,
    25.96170063452287,
    26.757675495147705,
    24.94927526692875,
    24.187424659729004,
    25.154938083584025,
    27.19538994188662,
    26.81839245557785,
    34.289908218383786,
    34.2440136273702,
    30.980402125868686,
    32.27454889016073,
    32.61460486123728
  ],
  "epsilon_history": [
    0.995,
    0.990025,
    0.985074875,
    0.9801495006250001,
    0.9752487531218751,
    0.9703725093562657,
    0.9655206468094844,
    0.960693043575437,
    0.9558895783575597,
    0.9511101304657719,
    0.946354579813443,
    0.9416228069143757,
    0.9369146928798039,
    0.9322301194154049,
    0.9275689688183278,
    0.9229311239742362,
    0.918316468354365,
    0.9137248860125932,
    0.9091562615825302,
    0.9046104802746175,
    0.9000874278732445,
    0.8955869907338783,
    0.8911090557802088,
    0.8866535105013078,
    0.8822202429488013
  ],
  "agent_metrics": {
    "epsilon": 0.8822202429488013,
    "training_step": 1264,
    "episode_count": 25,
    "buffer_size": 1327
  }
}