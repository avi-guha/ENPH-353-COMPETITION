# ğŸ¤– Reinforcement Learning Line Following System

## ğŸ“– Documentation Index

**Start here** based on what you need:

### ğŸš€ I want to get started quickly
â†’ Read **[QUICK_REFERENCE.md](QUICK_REFERENCE.md)** (3 min read)

### ğŸ“š I want the full user guide
â†’ Read **[RL_README.md](RL_README.md)** (15 min read)

### ğŸ”¬ I want technical details
â†’ Read **[PROJECT_SUMMARY.md](PROJECT_SUMMARY.md)** (20 min read)

### ğŸ¯ I want everything at once
â†’ Read **[COMPLETE_OVERVIEW.md](COMPLETE_OVERVIEW.md)** (10 min read)

---

## ğŸ® Quick Commands

```bash
# Train a model
./scripts/quickstart.py train --episodes 500 --render

# Test trained model
./scripts/quickstart.py test

# Debug camera processing
./scripts/quickstart.py visualize

# Check system status
./scripts/quickstart.py info
```

---

## ğŸ“‚ File Structure

```
robbie/
â”œâ”€â”€ ğŸ“– Documentation
â”‚   â”œâ”€â”€ QUICK_REFERENCE.md       â† 1-page cheat sheet
â”‚   â”œâ”€â”€ RL_README.md            â† Complete user guide  
â”‚   â”œâ”€â”€ PROJECT_SUMMARY.md      â† Technical deep dive
â”‚   â”œâ”€â”€ COMPLETE_OVERVIEW.md    â† Full system overview
â”‚   â””â”€â”€ INDEX.md                â† This file
â”‚
â”œâ”€â”€ ğŸ Core Scripts
â”‚   â”œâ”€â”€ rl_environment.py       â† Environment wrapper
â”‚   â”œâ”€â”€ dqn_model.py            â† Neural network
â”‚   â”œâ”€â”€ train_rl.py             â† Training script
â”‚   â”œâ”€â”€ run_inference.py        â† Testing script
â”‚   â”œâ”€â”€ visualize_bins.py       â† Debug tool
â”‚   â”œâ”€â”€ quickstart.py           â† CLI interface
â”‚   â””â”€â”€ config.py               â† Hyperparameters
â”‚
â”œâ”€â”€ ğŸ”§ Configuration
â”‚   â”œâ”€â”€ requirements.txt        â† Python dependencies
â”‚   â””â”€â”€ launch/
â”‚       â””â”€â”€ rl_training.launch  â† ROS launch file
â”‚
â”œâ”€â”€ ğŸ¤– Robot Definition
â”‚   â””â”€â”€ urdf/
â”‚       â””â”€â”€ robbie.xacro        â† Robot URDF (with collision sensor)
â”‚
â””â”€â”€ ğŸ’¾ Generated (during training)
    â””â”€â”€ checkpoints/
        â”œâ”€â”€ dqn_ep_*.pth        â† Model checkpoints
        â”œâ”€â”€ metrics_*.json      â† Training data
        â””â”€â”€ training_metrics.png â† Visualizations
```

---

## ğŸ¯ What This System Does

Uses **Deep Q-Network (DQN)** reinforcement learning to:
1. âœ… Process camera images into 20 binary features
2. âœ… Learn optimal steering and speed control
3. âœ… Follow white/yellow lines smoothly
4. âœ… Avoid collisions with obstacles (heavy penalty)
5. âœ… Navigate the course autonomously

---

## ğŸ§  Key Features

- **Intelligent State Representation**: Camera â†’ 20 bins (99.996% compression)
- **Multi-Objective Rewards**: Line following + speed + smoothness + safety
- **Safety First**: -100 penalty for collisions ensures cautious behavior
- **Production Ready**: Checkpointing, logging, visualization, documentation
- **Easy to Use**: Single command to train, single command to test

---

## ğŸ“Š Expected Performance

After **500 episodes** (~3-6 hours training):
- âœ… 80%+ success rate (completes course without collision)
- âœ… 0.4-0.5 m/s average speed
- âœ… Smooth steering with good line centering
- âœ… <10% collision rate

---

## ğŸš¦ Training Phases

| Phase | Episodes | Behavior | Avg Reward |
|-------|----------|----------|------------|
| **Exploration** | 1-100 | Random actions, crashes | -50 to 100 |
| **Learning** | 100-300 | Basic steering, some crashes | 100 to 500 |
| **Refinement** | 300-500 | Smooth navigation, rare crashes | 500+ |

---

## ğŸ”§ Quick Customization

Edit `scripts/config.py` to change:
- Robot speeds
- Steering angles  
- Reward values
- Neural network size
- Training parameters
- And more!

---

## ğŸ†˜ Need Help?

1. **System status**: Run `./scripts/quickstart.py info`
2. **Camera issues**: Run `./scripts/quickstart.py visualize`
3. **ROS problems**: Check `rostopic list`
4. **Training issues**: See troubleshooting in `RL_README.md`

---

## ğŸ“¦ What You Get

- âœ… **7 Python scripts** (2,700+ lines of production code)
- âœ… **4 documentation files** (comprehensive guides)
- âœ… **Complete DQN implementation** (experience replay, target network, etc.)
- âœ… **Visualization tools** (debug camera processing)
- âœ… **Configuration system** (easy hyperparameter tuning)
- âœ… **Checkpoint management** (save/resume training)

---

## ğŸ“ Technologies Used

- **ROS Noetic**: Robot Operating System
- **Gazebo**: 3D robot simulator
- **PyTorch**: Deep learning framework
- **OpenCV**: Computer vision
- **Reinforcement Learning**: DQN algorithm

---

## ğŸ¬ One-Line Quick Start

```bash
cd ~/ENPH-353-COMPETITION/src/robbie/scripts && ./quickstart.py train --episodes 500
```

That's it! The system handles everything else automatically.

---

## ğŸ“ˆ Monitoring Training

Watch these metrics in the terminal output:
- **Episode Reward**: Should increase over time
- **Collision Rate**: Should decrease
- **Epsilon**: Should decay from 1.0 to 0.05
- **Loss**: Should stabilize (not explode)

Plots are auto-saved to `checkpoints/training_metrics.png`

---

## ğŸ† Success Criteria

Your agent is well-trained when:
- âœ… Average reward > 500
- âœ… Episode length > 800 steps
- âœ… Collision rate < 10%
- âœ… Line stays in center bins 70%+ of time

---

## ğŸ”® Next Steps After Training

1. **Test the model**: `./quickstart.py test`
2. **Tune parameters**: Edit `config.py` and retrain
3. **Visualize behavior**: Use `--render` flag
4. **Deploy**: Run `./quickstart.py test --continuous`

---

## ğŸ“ Documentation Links

- [Quick Reference](QUICK_REFERENCE.md) - Cheat sheet
- [User Guide](RL_README.md) - Full tutorial
- [Technical Summary](PROJECT_SUMMARY.md) - Deep dive
- [Complete Overview](COMPLETE_OVERVIEW.md) - Everything

---

**ğŸš€ Ready to train your autonomous line-following robot? Start with the [Quick Reference](QUICK_REFERENCE.md)!**

---

*Deep Q-Network for Autonomous Line Following with Collision Avoidance*  
*Created: November 7, 2025*
